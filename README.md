# scan

Scrapy-based web crawler for site scanning and data extraction.

## Features
- Unlimited depth crawling
- Extracts metadata, content, links, images
- Selenium for JS rendering
- Storage: JSON, TXT, PostgreSQL, Elasticsearch, Kafka, RabbitMQ
- Queuing: RabbitMQ, Redis

## Setup
On Debian, run `install.sh` for dependencies.

## Usage
`python scan.py`  
Enter site URL to start crawl.

## License
GPL-3.0
